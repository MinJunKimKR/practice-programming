# [K8S] 왜 다른 pod를 같은 service에 두면 안될까?

오늘 회사에서 질문을 받았는데 너무나도 근원적인 질문이라서 답변을 시원하게 하지 못하였습니다.



wordpress + mysql을 사용하는 어플리케이션을 만든다고 가정해보겠습니다.

제가 알고있는 바로는,

wordpress pod와 WP-svc라는 서비스가 있고,

mysql pod와 mysql-svc라는 서비스가 있어서 

요청을 보낼때 mysql-svc에 요청을 보내는게 일반적으로 알고 있습니다.



하지만 오늘 받은 질문은이랬습니다

>   mysql pod를 WP-svc 로 함께 묶어서 쓰면되지,
> 왜 굳이 mysql-svc라는 서비스를 따로 만들어서 구조를 복잡하게 가져가냐?

이게 틀리다는걸 알면서도 명쾌한 답을 낼수가 없었어서 답답했습니다 

하지만 이것이 계기가 되어서 질문과 공부를 하게되었습니다.



제가 물어보고 다는 질문은 다음과 같았습니다.

### 1. 서비스와 pod는 어떤 기준으로 묶는지

### 2. 위의 예제에서 왜 mysql과 wordpress가 같은 service에 있으면 안되는지

### 3. 저 구조가 복잡하다는 말이 왜 틀렸는지



이제 하나씩 이유를 설명하겠습니다.

----



## 1.  서비스와 pod는 어떤 기준으로 묶는지

기본적으로 먼저 pod와 service의 개념에 대해서 알아야하는데, pod는 상황에 따라서 

자동적으로 생성되기도, 삭제 되기도 합니다. 

이때 마다 **pod는 새로운 IP를 부여 받기 때문에 매번 추적을 하기가 힘듭니다.**

따라서, Service를 이용해서 특정 pod에 추적이 되도록 합니다.

**Service의 Ip는 고정이 되어있기 때문입니다.**



**여기에서, 서비스는 2가지 역할이 있습니다.**

1. **서비스 디스커버리 : 위에서 설명드린대로 생성되고 사라지는 pod를 service이름으로 자동으로 찾을수 있게 해줍니다**
2. **로드밸런싱 : 기본적으로 확률방식의 로드밸런싱을 제공합니다.**

위의 이유로 서비스는 같은 역할(같은서비스)을 묶어서 로드밸런싱과 dns서비스를 같이 할때 묶습니다.



## 2.  위의 예제에서 왜 mysql과 wordpress가 같은 service에 있으면 안되는지

같은 word-svc라는 service에 mysql pod와 wordpress pod가 함께 존재한다고 가정해봅시다.

word-svc에 요청이 오게 될경우

**로드밸런싱에 따라 한번은 mysql pod로, 한번은 wordpress pod로 요청이 가게 될겁니다.**

만일, 운이 좋아서 wordpress로 간요청은 받아지겠지만 mysql로 가게된 요청은 작동을 아해서 문제를 일으킬겁니다.



또한, 1번에서 말한대로 **같은 pod여야 하지만 Mysql과 Wordpress는 전혀 수평적으로 동일하지 않습니다.** 

따라서, 같은 service로 구현되면 안됩니다.



그리고 **오토스케일링을 구현**할때에, **Wordpress에 많은 트래픽이 몰린다고 가정**했을시에, 

이게 꼭 **같은 량의 트래픽이 mysql에 간다고 보장할수 없습니다.**

따라서, wordpress만 오토스케일링 해주고 mysql은 유지하는등의 관리의 이점이 사라지게 됩니다.



추가로 1개의 service에 다수의 pod를 묶는게 가능한데, **이것을 멀티 포트 서비스 라고합니다.**

하지만 이것을 사용할때는 단일종류의 pod를 다수의 port를 사용하고자 할때 사용하는것이지 

**절대 다른 종류의 pod를 한개의 service에 연결하기 위함이 아닙니다**



**위의 이유들로 service란**

1. **1개의 endpoint 이다.**
2. **같은 pod를 묶어서 접근을 추상화 할수있는 방법이다.**
3. **생성되고 삭제되는 pod를 자동 디스커버리 해주기 위에 pod 앞단에 사용한다.**
4. **만일 다른 성격의 pod라고 한다면 다른 service로 분류하는것이 맞다.**



## 3. 저 구조가 복잡하다는 말이 왜 틀렸는지

**pod에 service를 붙이는것은 결합도를 느슨하게합니다(디커플링)**

따라서 **pod에 무슨일이 있던 (생성 및 삭제) 요청을 보내는 쪽은 service를 보게 되기 때문에 요청의 추상화가 가능해집니다.**

하지만, 1개의 service에 다른 2개의 pod를 붙이게 되면 강결합이 되버립니다.

이때, 변화에 약해져서 취약하게 됩니다.



또 하나, 기본적으로 **K8S는 MSA를 지향**합니다.

따라서, pod를 전부다 묶어버리는 방법도 가능은 하지만 이것은 더 이상 **MSA가 아닌 모놀리식 구조가 됩니다.**

그렇기에 **전부다 하나를 묶는다면 근본적으로 쿠버네티스를 사용할 이유가 없어지게 됩니다.**



----

처음엔 다소 황당한 질문이었지만 덕분에 약했던 개념을 훨씬 단단하게 다질수 있었던 계기가 되었습니다! 





----

# 쿠버네티스 클러스터 운영자를 위한 모니터링 정리

https://www.samsungsds.com/kr/insights/kubernetes_monitoring.html
https://www.redhat.com/ko/topics/containers/kubernetes-architecture

위의 삼성 SDS와 Red Hat의 글을 읽고 학습 목적으로 정리하였습니다.



## 쿠버네티스 개념 살펴보기

쿠버네티스는 리눅스 컨터이너의 장점을 활용하기 위해 다수의 머신(노드)에서 어플리케이션(컨테이너)를 실행하고 오케스트레이션 하는도구 입니다.

선언으로 정의된 (yaml or helm chart) 어플리케이션 디스크립터의 의도된상태(desired state)와 현재상태 (current state)가 일치 하는지 감지하고 일치하지 않을경우 이를 조정(reconcile)하는 연속적 과정에서 어플리케이션이 의도된 상태가 되기로 한다.

개발자는 개발된 컨테이너 이미지를 이미지 레지스트리(Image registry)에 푸시하고, 쿠버네티스 컨트롤 플레인(Control Plane)에 매니페스트(App descriptor)를 게시합니다. 

> **컨트롤 플레인** 
>
> 클러스터를 제어하는 쿠버네티스 구성 요소와 클러스터의 상태 및 구성에 관한 데이터가 함께 있습니다. 이 핵심 쿠버네티스 구성 요소는 컨테이너가 필요한 리소스를 갖고 충분한 횟수로 실행되도록 하는 중요한 작업을 맡습니다. 

컨트롤 플레인과 통신하는 각 노드의 Kubelet이 이 신호를 받고, 컨테이너 런타임(Docker)은 정의된 이미지를 이미지 레지스트리에서 가져와 컨테이너를 실행합니다.

> **kubelet**
>
> 각 컴퓨팅 노드에는 **컨트롤 플레인과 통신**하는 매우 작은 애플리케이션인 kubelet이 있습니다. kublet은 **컨테이너가 포드에서 실행**되게 합니다. 컨트롤 플레인에서 노드에 작업을 요청하는 경우 **kubelet이 이 작업을 실행**합니다.



## 환경의 모니터링 관점 변화

보통 각 서버는 특정 역할(WEB, DB 등)을 가지고 있고, 모니터링 에이전트를 설치해 정보를 수집하고, 이를 모니터링 백엔드로 전달합니다. 

이를 **Push-based 모니터링**이라고 합니다. 각 서버는 특정 역할을 가지므로 역할에 맞는 메트릭을 수집하도록 별도의 설정이 필요할 수도 있습니다.



반면 쿠버네티스 환경의 모니터링은 애플리케이션의 단위가 작아지고, 모니터링 대상도 동적으로 변경될 수 있습니다.

> 하나의 노드에 다양한 어플리케이션의 인스턴스가 실행되며 스케일링이나 자연회복에 의해 동적으로 변경됨

이러한 환경에서는 모니터링 백엔드가 모니터링 대상을 찾고 모니터링 메트릭을 수집해오는 것이 적절할 수도 있습니다. 

이를 **Pull-based 모니터링**이라고 합니다.

**프로메테우스(Prometheus)는 대표적인 Pull-based 모니터링 툴**입니다.

프로메테우스는 kube-apiserver로부터 **서비스를 디스커버리**하고, 각 대상에서 **메트릭을 수집(Scrape)**합니다. 

> **kube-apiserver**
>
> 쿠버네티스 클러스터와 상호 작용해야 하나요? API에 요청하세요. [쿠버네티스 API](https://www.redhat.com/ko/topics/containers/what-is-the-kubernetes-API)는 쿠버네티스 컨트롤 플레인의 프론트엔드로, 내부 및 외부 요청을 처리합니다. API 서버는 요청이 유효한지 판별하고 유효한 요청을 처리합니다. REST 호출이나 kubectl 커맨드라인 인터페이스 또는 kubeadm과 같은 기타 CLI(command-line interface)를 통해 API에 액세스할 수 있습니다.

(Push-based 모니터링 툴이 메트릭을 모니터링 백엔드로 전송하는 반면, Pull-based 모니터링 툴은 모니터링 백엔드가 대상에서 메트릭을 가져옵니다.)

![ㅇㅇ](https://image.samsungsds.com/kr/insights/kuber_img05.jpg?queryString=20210319023251)



## 모니터링 아키텍처

### **쿠버네티스 모니터링의 두 가지 파이프라인(Pipeline)**

쿠버네티스 모니터링을 쿠버네티스(혹은 컨트롤 플레인)의 컴포넌트가 직접 활용하는 정보와 이보다 많은 정보를 수집해 히스토리/통계 정보를 보여주는 모니터링 시스템 관점으로 나눠보겠습니다. 

이 흐름을 쿠버네티스 공식 사이트에서는 **리소스 메트릭 파이프라인(Resource Metrics Pipeline**)과 **완전한 메트릭 파이프라인(Full Metrics Pipeline)**으로 나눠서 설명하고 있습니다. 

리소스 메트릭 파이프라인은 **쿠버네티스의 컴포넌트가 활용하는 메트릭의 흐름**입니다.

쿠버네티스는 수집된 정보를 **kubectl top 명령으로 노출**해주고, 스케일링이 설정되어 있다면 자동 스케일링(Autoscaling)에 활용합니다. 

 ![](https://image.samsungsds.com/kr/insights/kuber_img06.jpg?queryString=20210319023251) 

metrics-server를 통해 수집된 모니터링 정보를 메모리에 저장하고 API 서버를 통해 노출해 kubectl top, scheduler, HPA와 같은 오브젝트에서 사용된다는 것을 나타냅니다. 쿠버네티스의 일부 기능은 Metric Server의 정보를 사용합니다.

다만, **이러한 정보는 순간의 정보를 가지고 있고, 다양한 정보를 수집하지 않으며, 장시간 저장하지 않습니다.** 이로 인해 두 번째 흐름인 **완전한 메트릭 파이프라인이 필요합니다.** 

이는 **기본 메트릭뿐만 아니라 다양한 메트릭을 수집하고, 이를 스토리지에 저장합니다.** 

완전한 메트릭 파이프라인 자체는 쿠버네티스에서 직접적으로 관여하지 않으며, CNCF 프로젝트 중 하나인 **프로메테우스를 활용할 수 있습니다.**

프로메테우스를 통해 **서비스 디스커버리(Service discovery), 메트릭 수집(Retrieval) 및 시계열 데이터베이스(TSDB, Time Series Database)를 통한 저장, 쿼리 엔진을 통한 PromQL 사용과 Alertmanager를 통한 통보**가 가능합니다.

 ![](https://prometheus.io/assets/architecture.png) 

### 정리

- 매트릭 파이프라인 종류
  - 리소스 매트릭 파이프라인, 완전한 매트릭 파이프라인 2가지 종류가 있다
- 리소스 매트릭 파이프라인
  - 쿠버네티스 컴포넌트의 매트릭 흐름
  - 스케일링 설정이 되어있다면 자동 스케일링에 활용함
  - 다만, 순간의 정보만 가지고 있기에 다양하게 수집하지 않으며 장기간 저장하지 않음
- 완전한 매트릭 파이프라인
  - Prometheus
  - 서비스 디커버리, 매트릭수집, 시계열 데이터베이스를 통한 저장을 한다



## 모니터링 컴포넌트

- **cAdvisor**: kubelet에 포함되어 노드, 파드, 컨테이너의 리소스 사용률을 수집하는 모듈

- **metrics server**: cAdvisor로부터 정보를 수집하는 도구로, 리소스 메트릭 파이프라인은 metrics server의 정보를 활용함
-  **node exporter**: Prometheus와 연동되는 **수집기(Exporter) 중 하나**로 노드의 HW, OS 메트릭을 수집하기 위한 도구



## 무엇을 모니터링해야 할까?

**클러스터 구성요소(노드 및 주요 컴포넌트)의 상태**

쿠버네티스 환경이라면 **쿠버네티스 자체를 모니터링**해야 합니다. 

컨트롤 플레인의 구성요소에 문제가 발생되어 사용자 애플리케이션이 배포되지 않거나 컨트롤러가 수행해야 하는 동작이 실패하는 상황이 발생할 수 있습니다. 클러스터의 주요 **컴포넌트와 더불어 노드의 상태도 확인이 필요하며 각각 Healthy, Ready 상태**이어야 합니다.



**노드의 리소스 가용량**

특정 노드에 관한 파드의 스케줄링은 노드에 할당되지 않은 리소스가 남아 있는 경우에 한해 가능합니다.

노드의 리소스 사용량 자체는 스케줄러가 수행하는 파드 스케줄링과 상관이 없습니다. 즉, 노드 가용량을 모니터링해야 하는 이유는 **전체 노드에 가용한 리소스(Allocatable)가 파드의 요청량(Request)보다 부족하면 파드가 더 이상 스케줄링되지 못하기 때문입니다.** 

필요한 경우 노드 리소스를 증설하거나, 노드를 추가해야 합니다. 가장 쉬운 방법은 **노드 상태를 확인하여 Allocated resources 부분의 각 CPU와 메모리 요청(Request)에 대한 퍼센티지를 확인**할 수 있습니다.



**워크로드(Workload) 이슈**

애플리케이션 자체 모니터링을 언급하지는 않았지만, **애플리케이션 프로세스 다운을 모니터링하는 부분이 있을 수 있습니다.** 파드에 적절한 라이브니스 프로브(liveness probe)가 설정되어 있는 경우, 혹은 OOMKilled되는 경우는 컨테이너의 재시작 횟수(Restart Count)가 지속적으로 증가하는지 모니터링해 볼 수 있습니다.

파드에서 한 가지 더 이야기 하고 싶은 것은 퍼시스턴트 볼륨(PV, Persistent Volume)입니다. **특정 애플리케이션은 PV의 용량 부족으로 문제가 될 수 있습니다.** 

한편, 퍼시스턴트 볼륨은 파드가 실행 중인 노드에 마운트되므로, (파일시스템 모니터링이 동적으로 반영된다면) **노드의 파일시스템 모니터링으로 가능합니다**

-----

# Devops 인프라 환경 구축 - 1. 전체 구조



이번에 Devops role을 맡아서 인프라를 처음부터 구축해볼 기회가 있었습니다.

어떤 방식으로 인프라를 구성하였는지 공유 하고 싶어서 이렇게 글을 씁니다.

전체적인 구조는 아래와 같습니다.

![](https://github.com/MinJunKimKR/photo_repo/blob/master/photos/CAPA%20SERVER-K8S%20%E1%84%80%E1%85%AE%E1%84%8C%E1%85%A9%E1%84%83%E1%85%A9.jpg?raw=true)

하나하나 설명을 해보겠습니다



### Local

제일위에 주황색으로 표시된 부분이 local에서 코드로 관리하는 부분입니다.

레포지토리는 크게 3가지로 구성되어있습니다.

1. Application

   Backend, Frontend와 같은 service에 대해 작성하는 레포입니다.

   이곳에서 서비스 개발을 한 코드가 있고 docker file로 만든뒤에

   Docker file로 만든다음에 ECR에 PUSH합니다.

2. CDK

   CDK 코드로 AWS리소스를 관리합니다.

   AWS console로 리소스를 생성 및 관리하니 개수가 늘어날수록 부담이 커졌습니다.

   하지만 CDK를 사용하니 자바스크립트 코드로 리소스를 관리할수 있다는점이 편해서 채택했습니다

3. K8S manifest

   운영 및 관리를 위해서 Helm을 사용하였습니다.

   yaml로 관리할 경우, development, staging, production과 같이 다중 stage환경으로 구성하려할때

   관리가 힘들지만, helm의 경우 helm chart를 이용해서 보다 간편하게 관리할수있어서 채택하게 되었습니다.

   

### AWS

가운데에 주황색 테두리로 표시되어있는 영역입니다.

리소스들은 aws console에 접속해서 직접 만드는것이 아닌 CDK를 사용해서 CouldFormation으로 관리됩니다.



- CouldFormation
- VPC
- ECR
  - Docker image화 되어있는 application 서비스가 Push되어집니다.
  - local registry와 고민했지만 namespace를 나눠서 development를 구성하는게 도입에 이득이라 생각했습니다.
- EKS
  - ECR에서 image를 pull해서 k8s환경을 구축합니다.
  - 1개의 클러스터에서 네임스페이스를 나눠서 쓰는 방식을 채택하였습니다.
    - 기본적으로 트래픽이 많지 않으며 초기 도입이기에 미니멀하게 시작하고 싶었기 때문입니다.
  - ELB와 연결되어서 외부트래픽을 받습니다.
- RDS
  - Prodction과 Staging DB를 분리하였습니다.
  - ID와 PW는 CDK에서 생성해서 Sceret master에서 확인할수 있습니다.

- ELB
  - Kong ingress controller를 통해서 생성됩니다.



















































