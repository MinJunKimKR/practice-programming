# [K8S] 왜 다른 pod를 같은 service에 두면 안될까?

오늘 회사에서 질문을 받았는데 너무나도 근원적인 질문이라서 답변을 시원하게 하지 못하였습니다.



wordpress + mysql을 사용하는 어플리케이션을 만든다고 가정해보겠습니다.

제가 알고있는 바로는,

wordpress pod와 WP-svc라는 서비스가 있고,

mysql pod와 mysql-svc라는 서비스가 있어서 

요청을 보낼때 mysql-svc에 요청을 보내는게 일반적으로 알고 있습니다.



하지만 오늘 받은 질문은이랬습니다

>   mysql pod를 WP-svc 로 함께 묶어서 쓰면되지,
> 왜 굳이 mysql-svc라는 서비스를 따로 만들어서 구조를 복잡하게 가져가냐?

이게 틀리다는걸 알면서도 명쾌한 답을 낼수가 없었어서 답답했습니다 

하지만 이것이 계기가 되어서 질문과 공부를 하게되었습니다.



제가 물어보고 다는 질문은 다음과 같았습니다.

### 1. 서비스와 pod는 어떤 기준으로 묶는지

### 2. 위의 예제에서 왜 mysql과 wordpress가 같은 service에 있으면 안되는지

### 3. 저 구조가 복잡하다는 말이 왜 틀렸는지



이제 하나씩 이유를 설명하겠습니다.

----



## 1.  서비스와 pod는 어떤 기준으로 묶는지

기본적으로 먼저 pod와 service의 개념에 대해서 알아야하는데, pod는 상황에 따라서 

자동적으로 생성되기도, 삭제 되기도 합니다. 

이때 마다 **pod는 새로운 IP를 부여 받기 때문에 매번 추적을 하기가 힘듭니다.**

따라서, Service를 이용해서 특정 pod에 추적이 되도록 합니다.

**Service의 Ip는 고정이 되어있기 때문입니다.**



**여기에서, 서비스는 2가지 역할이 있습니다.**

1. **서비스 디스커버리 : 위에서 설명드린대로 생성되고 사라지는 pod를 service이름으로 자동으로 찾을수 있게 해줍니다**
2. **로드밸런싱 : 기본적으로 확률방식의 로드밸런싱을 제공합니다.**

위의 이유로 서비스는 같은 역할(같은서비스)을 묶어서 로드밸런싱과 dns서비스를 같이 할때 묶습니다.



## 2.  위의 예제에서 왜 mysql과 wordpress가 같은 service에 있으면 안되는지

같은 word-svc라는 service에 mysql pod와 wordpress pod가 함께 존재한다고 가정해봅시다.

word-svc에 요청이 오게 될경우

**로드밸런싱에 따라 한번은 mysql pod로, 한번은 wordpress pod로 요청이 가게 될겁니다.**

만일, 운이 좋아서 wordpress로 간요청은 받아지겠지만 mysql로 가게된 요청은 작동을 아해서 문제를 일으킬겁니다.



또한, 1번에서 말한대로 **같은 pod여야 하지만 Mysql과 Wordpress는 전혀 수평적으로 동일하지 않습니다.** 

따라서, 같은 service로 구현되면 안됩니다.



그리고 **오토스케일링을 구현**할때에, **Wordpress에 많은 트래픽이 몰린다고 가정**했을시에, 

이게 꼭 **같은 량의 트래픽이 mysql에 간다고 보장할수 없습니다.**

따라서, wordpress만 오토스케일링 해주고 mysql은 유지하는등의 관리의 이점이 사라지게 됩니다.



추가로 1개의 service에 다수의 pod를 묶는게 가능한데, **이것을 멀티 포트 서비스 라고합니다.**

하지만 이것을 사용할때는 단일종류의 pod를 다수의 port를 사용하고자 할때 사용하는것이지 

**절대 다른 종류의 pod를 한개의 service에 연결하기 위함이 아닙니다**



**위의 이유들로 service란**

1. **1개의 endpoint 이다.**
2. **같은 pod를 묶어서 접근을 추상화 할수있는 방법이다.**
3. **생성되고 삭제되는 pod를 자동 디스커버리 해주기 위에 pod 앞단에 사용한다.**
4. **만일 다른 성격의 pod라고 한다면 다른 service로 분류하는것이 맞다.**



## 3. 저 구조가 복잡하다는 말이 왜 틀렸는지

**pod에 service를 붙이는것은 결합도를 느슨하게합니다(디커플링)**

따라서 **pod에 무슨일이 있던 (생성 및 삭제) 요청을 보내는 쪽은 service를 보게 되기 때문에 요청의 추상화가 가능해집니다.**

하지만, 1개의 service에 다른 2개의 pod를 붙이게 되면 강결합이 되버립니다.

이때, 변화에 약해져서 취약하게 됩니다.



또 하나, 기본적으로 **K8S는 MSA를 지향**합니다.

따라서, pod를 전부다 묶어버리는 방법도 가능은 하지만 이것은 더 이상 **MSA가 아닌 모놀리식 구조가 됩니다.**

그렇기에 **전부다 하나를 묶는다면 근본적으로 쿠버네티스를 사용할 이유가 없어지게 됩니다.**



----

처음엔 다소 황당한 질문이었지만 덕분에 약했던 개념을 훨씬 단단하게 다질수 있었던 계기가 되었습니다! 





----

# 쿠버네티스 클러스터 운영자를 위한 모니터링 정리

https://www.samsungsds.com/kr/insights/kubernetes_monitoring.html
https://www.redhat.com/ko/topics/containers/kubernetes-architecture

위의 삼성 SDS와 Red Hat의 글을 읽고 학습 목적으로 정리하였습니다.



## 쿠버네티스 개념 살펴보기

쿠버네티스는 리눅스 컨터이너의 장점을 활용하기 위해 다수의 머신(노드)에서 어플리케이션(컨테이너)를 실행하고 오케스트레이션 하는도구 입니다.

선언으로 정의된 (yaml or helm chart) 어플리케이션 디스크립터의 의도된상태(desired state)와 현재상태 (current state)가 일치 하는지 감지하고 일치하지 않을경우 이를 조정(reconcile)하는 연속적 과정에서 어플리케이션이 의도된 상태가 되기로 한다.

개발자는 개발된 컨테이너 이미지를 이미지 레지스트리(Image registry)에 푸시하고, 쿠버네티스 컨트롤 플레인(Control Plane)에 매니페스트(App descriptor)를 게시합니다. 

> **컨트롤 플레인** 
>
> 클러스터를 제어하는 쿠버네티스 구성 요소와 클러스터의 상태 및 구성에 관한 데이터가 함께 있습니다. 이 핵심 쿠버네티스 구성 요소는 컨테이너가 필요한 리소스를 갖고 충분한 횟수로 실행되도록 하는 중요한 작업을 맡습니다. 

컨트롤 플레인과 통신하는 각 노드의 Kubelet이 이 신호를 받고, 컨테이너 런타임(Docker)은 정의된 이미지를 이미지 레지스트리에서 가져와 컨테이너를 실행합니다.

> **kubelet**
>
> 각 컴퓨팅 노드에는 컨트롤 플레인과 통신하는 매우 작은 애플리케이션인 kubelet이 있습니다. kublet은 컨테이너가 포드에서 실행되게 합니다. 컨트롤 플레인에서 노드에 작업을 요청하는 경우 kubelet이 이 작업을 실행합니다.



## 환경의 모니터링 관점 변화

보통 각 서버는 특정 역할(WEB, DB 등)을 가지고 있고, 모니터링 에이전트를 설치해 정보를 수집하고, 이를 모니터링 백엔드로 전달합니다. 

이를 **Push-based 모니터링**이라고 합니다. 각 서버는 특정 역할을 가지므로 역할에 맞는 메트릭을 수집하도록 별도의 설정이 필요할 수도 있습니다.



반면 쿠버네티스 환경의 모니터링은 애플리케이션의 단위가 작아지고, 모니터링 대상도 동적으로 변경될 수 있습니다.

> 하나의 노드에 다양한 어플리케이션의 인스턴스가 실행되며 스케일링이나 자연회복에 의해 동적으로 변경됨

이러한 환경에서는 모니터링 백엔드가 모니터링 대상을 찾고 모니터링 메트릭을 수집해오는 것이 적절할 수도 있습니다. 

이를 **Pull-based 모니터링**이라고 합니다.

프로메테우스(Prometheus)는 대표적인 Pull-based 모니터링 툴입니다.

프로메테우스는 kube-apiserver로부터 서비스를 디스커버리하고, 각 대상에서 메트릭을 수집(Scrape)합니다. 

> **kube-apiserver**
>
> 쿠버네티스 클러스터와 상호 작용해야 하나요? API에 요청하세요. [쿠버네티스 API](https://www.redhat.com/ko/topics/containers/what-is-the-kubernetes-API)는 쿠버네티스 컨트롤 플레인의 프론트엔드로, 내부 및 외부 요청을 처리합니다. API 서버는 요청이 유효한지 판별하고 유효한 요청을 처리합니다. REST 호출이나 kubectl 커맨드라인 인터페이스 또는 kubeadm과 같은 기타 CLI(command-line interface)를 통해 API에 액세스할 수 있습니다.

(Push-based 모니터링 툴이 메트릭을 모니터링 백엔드로 전송하는 반면, Pull-based 모니터링 툴은 모니터링 백엔드가 대상에서 메트릭을 가져옵니다.)

![ㅇㅇ](https://image.samsungsds.com/kr/insights/kuber_img05.jpg?queryString=20210319023251)



## 모니터링 아키텍처

### **쿠버네티스 모니터링의 두 가지 파이프라인(Pipeline)**

쿠버네티스 모니터링을 쿠버네티스(혹은 컨트롤 플레인)의 컴포넌트가 직접 활용하는 정보와 이보다 많은 정보를 수집해 히스토리/통계 정보를 보여주는 모니터링 시스템 관점으로 나눠보겠습니다. 

이 흐름을 쿠버네티스 공식 사이트에서는 **리소스 메트릭 파이프라인(Resource Metrics Pipeline**)과 **완전한 메트릭 파이프라인(Full Metrics Pipeline)**으로 나눠서 설명하고 있습니다. 

리소스 메트릭 파이프라인은 **쿠버네티스의 컴포넌트가 활용하는 메트릭의 흐름**입니다.

쿠버네티스는 수집된 정보를 **kubectl top 명령으로 노출**해주고, 스케일링이 설정되어 있다면 자동 스케일링(Autoscaling)에 활용합니다. 

 ![](https://image.samsungsds.com/kr/insights/kuber_img06.jpg?queryString=20210319023251) 

metrics-server를 통해 수집된 모니터링 정보를 메모리에 저장하고 API 서버를 통해 노출해 kubectl top, scheduler, HPA와 같은 오브젝트에서 사용된다는 것을 나타냅니다. 쿠버네티스의 일부 기능은 Metric Server의 정보를 사용합니다.

다만, **이러한 정보는 순간의 정보를 가지고 있고, 다양한 정보를 수집하지 않으며, 장시간 저장하지 않습니다.** 이로 인해 두 번째 흐름인 **완전한 메트릭 파이프라인이 필요합니다.** 

이는 **기본 메트릭뿐만 아니라 다양한 메트릭을 수집하고, 이를 스토리지에 저장합니다.** 

완전한 메트릭 파이프라인 자체는 쿠버네티스에서 직접적으로 관여하지 않으며, CNCF 프로젝트 중 하나인 **프로메테우스를 활용할 수 있습니다.**

프로메테우스를 통해 **서비스 디스커버리(Service discovery), 메트릭 수집(Retrieval) 및 시계열 데이터베이스(TSDB, Time Series Database)를 통한 저장, 쿼리 엔진을 통한 PromQL 사용과 Alertmanager를 통한 통보**가 가능합니다.

 ![](https://image.samsungsds.com/kr/insights/kuber_img07.jpg?queryString=20210319023251) 

### 정리

- 매트릭 파이프라인 종류
  - 리소스 매트릭 파이프라인, 완전한 매트릭 파이프라인 2가지 종류가 있다
- 리소스 매트릭 파이프라인
  - 
- 완전한 매트릭 파이프라인





























